<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>WebAR Face Stylization</title>

  <!-- ✅ 引入 TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.0.0/dist/tf.min.js"></script>

  <!-- ✅ MindAR for image tracking -->
  <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.1.4/dist/mindar-image-three.prod.js"></script>

  <!-- ✅ face-api.js 瀏覽器專用版本 (避免 exports 錯誤) -->
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <!-- ✅ ml5.js for style transfer -->
  <script defer src="https://unpkg.com/ml5@latest/dist/ml5.min.js"></script>

  <style>
    body { margin: 0; overflow: hidden; }
    canvas, video { position: absolute; top: 0; left: 0; }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline width="640" height="480" style="display:none;"></video>
  <canvas id="output" width="640" height="480"></canvas>
  <img id="bg" src="b.jpg" style="display: none" />
  <canvas id="face-canvas" width="150" height="150" style="display:none;"></canvas>

  <script>
    window.addEventListener('DOMContentLoaded', async () => {
      const video = document.getElementById('video');
      const canvas = document.getElementById('output');
      const ctx = canvas.getContext('2d');
      const bgImg = document.getElementById('bg');
      const faceCanvas = document.getElementById('face-canvas');
      const faceCtx = faceCanvas.getContext('2d');

      let faceDetectionActive = false;
      let styleTransfer;

      // Initialize the camera
      async function initCamera() {
        const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' }, audio: false });
        video.srcObject = stream;
        await new Promise(resolve => video.onloadedmetadata = resolve);
      }

      // Load models
      async function loadModels() {
        await tf.ready();  // Make sure TensorFlow.js is ready
        await tf.setBackend('webgpu'); // Set the backend if necessary
        console.log("✅ TensorFlow.js initialized and set to 'webgpu' backend");

        await faceapi.nets.tinyFaceDetector.loadFromUri('./models');
        styleTransfer = await ml5.styleTransfer('https://storage.googleapis.com/ml5-style-transfer/mosaic', () => {
          console.log("✅ Style model loaded");
        });
      }

      // Render frames
      async function renderFrame() {
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        if (faceDetectionActive) {
          const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
          if (detections.length > 0) {
            ctx.drawImage(bgImg, 0, 0, canvas.width, canvas.height);
            for (const det of detections) {
              const { x, y, width, height } = det.box;
              faceCtx.clearRect(0, 0, faceCanvas.width, faceCanvas.height);
              faceCtx.drawImage(video, x, y, width, height, 0, 0, faceCanvas.width, faceCanvas.height);

              await styleTransfer.transfer(faceCanvas, (err, result) => {
                if (err || !result) {
